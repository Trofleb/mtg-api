{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TOKEN = os.getenv(\"IK_API_KEY\")\n",
    "PRODUCT_ID = os.getenv(\"IK_PRODUCT_ID\")\n",
    "URL = f\"https://api.infomaniak.com/1/ai/{PRODUCT_ID}/openai\"\n",
    "MODEL_LLM = \"mistral24b\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "llm_base_client = OpenAI(\n",
    "    api_key=TOKEN,\n",
    "    base_url=URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY_RUNPOD = os.getenv(\"API_KEY_OCR_LLM\", \"\")\n",
    "RUNPOD_ENDPOINT_ID = \"5hwezmg13oviky\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY_RUNPOD,\n",
    "    base_url=f\"https://api.runpod.ai/v2/{RUNPOD_ENDPOINT_ID}/openai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a base prompt that will be used for training and running the fine tuned model\n",
    "# It's simplified from the prompt which was used to generate the silver data, and can change from dataset to dataset\n",
    "def build_finetuning_prompt(base_text: str) -> str:\n",
    "    return (\n",
    "        f\"Below is the image of one page of a document, as well as some raw textual content that was previously extracted for it. \"\n",
    "        f\"Just return the plain text representation of this document as if you were reading it naturally.\\n\"\n",
    "        f\"Do not hallucinate.\\n\"\n",
    "        f\"RAW_TEXT_START\\n{base_text}\\nRAW_TEXT_END\"\n",
    "    )\n",
    "\n",
    "\n",
    "TOKEN = \"x\"\n",
    "URL = \"http://localhost:11434/\"\n",
    "MODEL = \"allenai/olmOCR-7B-0225-preview\"\n",
    "\n",
    "\n",
    "def process_image(image_base64: str):\n",
    "    # Build the full prompt\n",
    "    prompt = build_finetuning_prompt(\n",
    "        \"PV de réunion de l'assemblée générale de l'association Magic Genève\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.8,\n",
    "        max_completion_tokens=2000,\n",
    "        max_tokens=2001,\n",
    "        presence_penalty=0.3,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "with open(\"../data/to_ocr/PV manuscrit.pdf\", \"rb\") as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = process_image(image_base64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "pages_extracted = []\n",
    "with open(\"../data/to_extract/PV manuscrit.pdf\") as file:\n",
    "    doc = pymupdf.open(file)\n",
    "    for index, page in enumerate(doc):\n",
    "        pix = page.get_pixmap()\n",
    "        img = base64.b64encode(pix.tobytes(\"png\")).decode()\n",
    "        text = page.get_text().encode(\"utf8\")\n",
    "        prompt = build_finetuning_prompt(\"No text available\")\n",
    "\n",
    "        # Build the full prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print(f\"Processing page {index + 1}\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            max_completion_tokens=2000,\n",
    "            max_tokens=2001,\n",
    "            presence_penalty=0.3,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        pages_extracted.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(pages_extracted[1].choices[0].message.content)[\"natural_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = []\n",
    "file_path = \"../data/to_extract/PV manuscrit.pdf\"\n",
    "with open(file_path) as file:\n",
    "    doc = pymupdf.open(file)\n",
    "    for index, page in enumerate(doc):\n",
    "        pix = page.get_pixmap()\n",
    "        img = base64.b64encode(pix.tobytes(\"png\")).decode()\n",
    "        prompt = build_finetuning_prompt(\n",
    "            json.loads(pages_extracted[index].choices[0].message.content)[\n",
    "                \"natural_text\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Build the full prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print(f\"Processing page {index + 1}\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            max_completion_tokens=2000,\n",
    "            max_tokens=2001,\n",
    "            presence_penalty=0.3,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        response_2.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_1_1.txt\", \"w\") as f:\n",
    "    f.write(json.loads(pages_extracted[0].choices[0].message.content)[\"natural_text\"])\n",
    "with open(\"text_1_2.txt\", \"w\") as f:\n",
    "    f.write(json.loads(pages_extracted[1].choices[0].message.content)[\"natural_text\"])\n",
    "with open(\"text_2_1.txt\", \"w\") as f:\n",
    "    f.write(json.loads(response_2[0].choices[0].message.content)[\"natural_text\"])\n",
    "with open(\"text_2_2.txt\", \"w\") as f:\n",
    "    f.write(json.loads(response_2[1].choices[0].message.content)[\"natural_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_stream = llm_base_client.chat.completions.create(\n",
    "    model=MODEL_LLM,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Voici le text extrait d'une prise de note manuscrite: {text}. Est-ce que tu peux me corriger les erreurs d'ocr ?\",\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_tokens=4000,\n",
    "    stream=True,\n",
    ")\n",
    "# Stream the response\n",
    "for response in response_stream:\n",
    "    print(response.choices[0].delta.content or \"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.datalab.to/api/v1/marker\"\n",
    "\n",
    "form_data = {\n",
    "    \"file\": (file_path, open(file_path, \"rb\"), \"application/pdf\"),\n",
    "    \"langs\": (None, \"English\"),\n",
    "    \"force_ocr\": (None, False),\n",
    "    \"paginate\": (None, False),\n",
    "    \"output_format\": (None, \"markdown\"),\n",
    "    \"use_llm\": (None, False),\n",
    "    \"strip_existing_ocr\": (None, False),\n",
    "    \"disable_image_extraction\": (None, False),\n",
    "}\n",
    "\n",
    "headers = {\"X-Api-Key\": os.getenv(\"MARKER_OCR_KEY\")}\n",
    "\n",
    "response = requests.post(url, files=form_data, headers=headers)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "res = get(data[\"request_check_url\"], headers=headers)\n",
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"success\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.md\", \"w\") as f:\n",
    "    f.write(data[\"markdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
